{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes Microservices Observability Data Generator\n",
    "\n",
    "This notebook generates a **realistic Kubernetes-deployed e-commerce platform** with:\n",
    "\n",
    "**Indices Created:**\n",
    "- `application-logs` - Application logs from all microservices\n",
    "- `kubernetes-events` - K8s cluster events (pod restarts, scaling, failures)\n",
    "- `system-metrics` - CPU, memory, network, disk metrics per pod/node\n",
    "- `distributed-traces` - Request traces spanning multiple services\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "                    ┌─────────────────┐\n",
    "                    │   Ingress/LB    │\n",
    "                    └────────┬────────┘\n",
    "                             │\n",
    "                    ┌────────▼────────┐\n",
    "                    │   API Gateway   │ (3 replicas)\n",
    "                    └────────┬────────┘\n",
    "           ┌─────────────────┼─────────────────┐\n",
    "           │                 │                 │\n",
    "    ┌──────▼──────┐   ┌──────▼──────┐   ┌──────▼──────┐\n",
    "    │ User Service│   │Order Service│   │Search Svc   │\n",
    "    │ (2 replicas)│   │(3 replicas) │   │(2 replicas) │\n",
    "    └──────┬──────┘   └──────┬──────┘   └─────────────┘\n",
    "           │                 │\n",
    "    ┌──────▼──────┐   ┌──────▼──────┐   ┌─────────────┐\n",
    "    │ Auth Service│   │Payment Svc  │   │Recommendation│\n",
    "    │ (2 replicas)│   │(2 replicas) │   │(2 replicas) │\n",
    "    └─────────────┘   └──────┬──────┘   └─────────────┘\n",
    "                             │\n",
    "                      ┌──────▼──────┐   ┌─────────────┐\n",
    "                      │Inventory Svc│   │Notification │\n",
    "                      │(2 replicas) │   │(1 replica)  │\n",
    "                      └─────────────┘   └─────────────┘\n",
    "```\n",
    "\n",
    "**Simulated Incidents:**\n",
    "1. Memory leak in recommendation-engine causing OOM kills\n",
    "2. Database connection pool exhaustion in order-service\n",
    "3. Cascading timeout failures from payment-service\n",
    "4. Network partition affecting inventory-service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "from elasticsearch import Elasticsearch, helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'scheme': 'http'}])\n",
    "\n",
    "# Verify connection\n",
    "if es.ping():\n",
    "    print(\"Connected to Elasticsearch!\")\n",
    "else:\n",
    "    raise Exception(\"Could not connect to Elasticsearch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kubernetes cluster configuration\n",
    "K8S_CLUSTER = \"prod-us-east-1\"\n",
    "K8S_NAMESPACE = \"ecommerce\"\n",
    "\n",
    "# Node pool (simulating a 5-node cluster)\n",
    "K8S_NODES = [\n",
    "    {\"name\": \"node-pool-1-abc12\", \"zone\": \"us-east-1a\", \"instance_type\": \"m5.xlarge\", \"cpu_cores\": 4, \"memory_gb\": 16},\n",
    "    {\"name\": \"node-pool-1-def34\", \"zone\": \"us-east-1b\", \"instance_type\": \"m5.xlarge\", \"cpu_cores\": 4, \"memory_gb\": 16},\n",
    "    {\"name\": \"node-pool-1-ghi56\", \"zone\": \"us-east-1c\", \"instance_type\": \"m5.xlarge\", \"cpu_cores\": 4, \"memory_gb\": 16},\n",
    "    {\"name\": \"node-pool-2-jkl78\", \"zone\": \"us-east-1a\", \"instance_type\": \"m5.2xlarge\", \"cpu_cores\": 8, \"memory_gb\": 32},\n",
    "    {\"name\": \"node-pool-2-mno90\", \"zone\": \"us-east-1b\", \"instance_type\": \"m5.2xlarge\", \"cpu_cores\": 8, \"memory_gb\": 32},\n",
    "]\n",
    "\n",
    "# Services with full Kubernetes metadata\n",
    "services = []\n",
    "service_definitions = [\n",
    "    {\"name\": \"api-gateway\", \"replicas\": 3, \"cpu_request\": \"500m\", \"memory_request\": \"512Mi\", \"image\": \"ecommerce/api-gateway:2.4.1\"},\n",
    "    {\"name\": \"user-service\", \"replicas\": 2, \"cpu_request\": \"250m\", \"memory_request\": \"256Mi\", \"image\": \"ecommerce/user-service:1.8.3\"},\n",
    "    {\"name\": \"auth-service\", \"replicas\": 2, \"cpu_request\": \"200m\", \"memory_request\": \"256Mi\", \"image\": \"ecommerce/auth-service:3.1.0\"},\n",
    "    {\"name\": \"order-service\", \"replicas\": 3, \"cpu_request\": \"500m\", \"memory_request\": \"512Mi\", \"image\": \"ecommerce/order-service:2.2.7\"},\n",
    "    {\"name\": \"payment-service\", \"replicas\": 2, \"cpu_request\": \"300m\", \"memory_request\": \"384Mi\", \"image\": \"ecommerce/payment-service:1.5.2\"},\n",
    "    {\"name\": \"inventory-service\", \"replicas\": 2, \"cpu_request\": \"250m\", \"memory_request\": \"256Mi\", \"image\": \"ecommerce/inventory-service:1.9.0\"},\n",
    "    {\"name\": \"notification-service\", \"replicas\": 1, \"cpu_request\": \"100m\", \"memory_request\": \"128Mi\", \"image\": \"ecommerce/notification-service:1.3.4\"},\n",
    "    {\"name\": \"search-service\", \"replicas\": 2, \"cpu_request\": \"400m\", \"memory_request\": \"1Gi\", \"image\": \"ecommerce/search-service:2.0.1\"},\n",
    "    {\"name\": \"recommendation-engine\", \"replicas\": 2, \"cpu_request\": \"1000m\", \"memory_request\": \"2Gi\", \"image\": \"ecommerce/recommendation:3.5.0\"},\n",
    "    {\"name\": \"cache-service\", \"replicas\": 3, \"cpu_request\": \"200m\", \"memory_request\": \"1Gi\", \"image\": \"redis:7.2-alpine\"},\n",
    "]\n",
    "\n",
    "# Generate pod instances for each service\n",
    "for svc_def in service_definitions:\n",
    "    for replica_idx in range(svc_def[\"replicas\"]):\n",
    "        pod_suffix = f\"{uuid.uuid4().hex[:5]}\"\n",
    "        node = random.choice(K8S_NODES)\n",
    "        services.append({\n",
    "            \"name\": svc_def[\"name\"],\n",
    "            \"k8s.pod.name\": f\"{svc_def['name']}-{replica_idx}-{pod_suffix}\",\n",
    "            \"k8s.pod.uid\": str(uuid.uuid4()),\n",
    "            \"k8s.namespace\": K8S_NAMESPACE,\n",
    "            \"k8s.node.name\": node[\"name\"],\n",
    "            \"k8s.deployment.name\": svc_def[\"name\"],\n",
    "            \"k8s.replicaset.name\": f\"{svc_def['name']}-{uuid.uuid4().hex[:10]}\",\n",
    "            \"container.image.name\": svc_def[\"image\"],\n",
    "            \"container.id\": f\"docker://{uuid.uuid4().hex}\",\n",
    "            \"host.name\": node[\"name\"],\n",
    "            \"cloud.availability_zone\": node[\"zone\"],\n",
    "            \"env\": \"production\",\n",
    "            \"cpu_request\": svc_def[\"cpu_request\"],\n",
    "            \"memory_request\": svc_def[\"memory_request\"],\n",
    "        })\n",
    "\n",
    "print(f\"Generated {len(services)} pod instances across {len(K8S_NODES)} nodes\")\n",
    "\n",
    "log_levels = [\"DEBUG\", \"INFO\", \"WARN\", \"ERROR\", \"FATAL\"]\n",
    "log_level_weights = [10, 60, 20, 8, 2]\n",
    "\n",
    "http_status_codes = [200, 201, 204, 301, 302, 400, 401, 403, 404, 408, 429, 500, 502, 503, 504]\n",
    "http_status_weights = [50, 10, 5, 2, 2, 5, 3, 2, 8, 2, 3, 4, 1, 2, 1]\n",
    "\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15\",\n",
    "    \"Mozilla/5.0 (Linux; Android 14) AppleWebKit/537.36 Chrome/120.0.0.0 Mobile\",\n",
    "    \"PostmanRuntime/7.35.0\",\n",
    "    \"python-requests/2.31.0\",\n",
    "    \"curl/8.4.0\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error message templates by service - realistic production errors\n",
    "error_templates = {\n",
    "    \"api-gateway\": [\n",
    "        \"Connection timeout to upstream service {service} after {timeout}ms\",\n",
    "        \"Rate limit exceeded for client IP {ip} - {requests} requests in {window}s\",\n",
    "        \"Circuit breaker OPEN for service {service}, failing fast\",\n",
    "        \"SSL handshake failed with upstream: {reason}\",\n",
    "        \"Request body too large: {size}MB exceeds limit of 10MB\",\n",
    "        \"Invalid JWT token: {reason}\",\n",
    "        \"Upstream service {service} returned {status}: {message}\",\n",
    "    ],\n",
    "    \"user-service\": [\n",
    "        \"Failed to authenticate user {user_id}: {reason}\",\n",
    "        \"Database connection pool exhausted, {waiting} requests waiting\",\n",
    "        \"User {user_id} not found in database\",\n",
    "        \"Password hash verification failed for user {user_id}\",\n",
    "        \"Email validation failed for {email}: {reason}\",\n",
    "        \"Session expired for user {user_id}, last activity {minutes} minutes ago\",\n",
    "        \"Failed to send verification email to {email}: SMTP error {code}\",\n",
    "    ],\n",
    "    \"order-service\": [\n",
    "        \"Order {order_id} processing failed: insufficient inventory for SKU {sku}\",\n",
    "        \"Payment authorization failed for order {order_id}: {reason}\",\n",
    "        \"Order {order_id} stuck in {status} state for {hours} hours\",\n",
    "        \"Failed to calculate shipping for order {order_id}: invalid address\",\n",
    "        \"Duplicate order detected: {order_id} matches existing order\",\n",
    "        \"Order cancellation failed: order {order_id} already shipped\",\n",
    "        \"Tax calculation service timeout for order {order_id}\",\n",
    "    ],\n",
    "    \"payment-service\": [\n",
    "        \"Payment gateway {gateway} returned error: {error_code} - {message}\",\n",
    "        \"Card validation failed for transaction {txn_id}: {reason}\",\n",
    "        \"Refund request failed: original transaction not found\",\n",
    "        \"3DS authentication required but not provided for transaction {txn_id}\",\n",
    "        \"Payment timeout: transaction {txn_id} did not complete in {timeout}s\",\n",
    "        \"Fraud detection triggered for transaction {txn_id}: risk score {score}\",\n",
    "        \"Currency conversion failed: {from_curr} to {to_curr} rate unavailable\",\n",
    "    ],\n",
    "    \"inventory-service\": [\n",
    "        \"Stock level mismatch for SKU {sku}: expected {expected}, actual {actual}\",\n",
    "        \"Warehouse {warehouse_id} sync failed: connection refused\",\n",
    "        \"Reserved inventory expired for order {order_id}, releasing {quantity} units\",\n",
    "        \"Low stock alert: SKU {sku} has only {quantity} units remaining\",\n",
    "        \"Failed to update inventory: optimistic locking conflict for SKU {sku}\",\n",
    "    ],\n",
    "    \"notification-service\": [\n",
    "        \"Push notification failed for device {device_id}: token expired\",\n",
    "        \"Email delivery failed to {email}: bounced with code {code}\",\n",
    "        \"SMS gateway error: {provider} returned {error_code}\",\n",
    "        \"Notification queue backlog: {count} messages pending, oldest {age}s\",\n",
    "        \"Template rendering failed for {template}: missing variable {var}\",\n",
    "    ],\n",
    "    \"search-service\": [\n",
    "        \"Elasticsearch cluster health RED: {shards} unassigned shards\",\n",
    "        \"Search query timeout after {timeout}ms for query: {query}\",\n",
    "        \"Index {index} not found, falling back to default search\",\n",
    "        \"Aggregation query too expensive: {buckets} buckets requested\",\n",
    "        \"Reindex operation failed at document {doc_id}: {reason}\",\n",
    "    ],\n",
    "    \"recommendation-engine\": [\n",
    "        \"Model inference failed: GPU memory exhausted\",\n",
    "        \"Feature store connection timeout after {timeout}ms\",\n",
    "        \"Cold start problem for new user {user_id}: no interaction history\",\n",
    "        \"Model version mismatch: expected v{expected}, got v{actual}\",\n",
    "        \"Recommendation cache miss rate {percent}% exceeds threshold\",\n",
    "    ],\n",
    "    \"cache-service\": [\n",
    "        \"Redis cluster node {node} unreachable, failover initiated\",\n",
    "        \"Cache eviction storm: {evicted} keys evicted in {seconds}s\",\n",
    "        \"Memory usage critical: {percent}% of max, consider scaling\",\n",
    "        \"Key {key} serialization failed: object too large\",\n",
    "        \"Distributed lock acquisition timeout for key {key}\",\n",
    "    ],\n",
    "    \"auth-service\": [\n",
    "        \"Brute force attack detected from IP {ip}: {attempts} failed attempts\",\n",
    "        \"OAuth provider {provider} returned error: {error}\",\n",
    "        \"Token refresh failed for user {user_id}: refresh token revoked\",\n",
    "        \"MFA verification failed for user {user_id}: code expired\",\n",
    "        \"API key revoked due to suspicious activity\",\n",
    "        \"LDAP sync failed: connection to {server} refused\",\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info/success message templates\n",
    "info_templates = {\n",
    "    \"api-gateway\": [\n",
    "        \"Request {method} {path} completed in {duration}ms with status {status}\",\n",
    "        \"New client connection from {ip}, total active connections: {count}\",\n",
    "        \"Rate limit reset for client {ip}\",\n",
    "        \"Circuit breaker CLOSED for service {service}, resuming normal operation\",\n",
    "        \"Health check passed for all upstream services\",\n",
    "    ],\n",
    "    \"user-service\": [\n",
    "        \"User {user_id} successfully authenticated from {ip}\",\n",
    "        \"New user registration completed: {user_id} ({email})\",\n",
    "        \"Password changed successfully for user {user_id}\",\n",
    "        \"User profile updated: {user_id} changed {fields}\",\n",
    "        \"Session created for user {user_id}, expires in {hours} hours\",\n",
    "    ],\n",
    "    \"order-service\": [\n",
    "        \"Order {order_id} created successfully, total: ${amount}\",\n",
    "        \"Order {order_id} status changed: {from_status} -> {to_status}\",\n",
    "        \"Order {order_id} shipped via {carrier}, tracking: {tracking}\",\n",
    "        \"Order {order_id} delivered to {city}, {country}\",\n",
    "        \"Bulk order import completed: {count} orders processed\",\n",
    "    ],\n",
    "    \"payment-service\": [\n",
    "        \"Payment {txn_id} authorized successfully: ${amount}\",\n",
    "        \"Payment {txn_id} captured: ${amount} via {method}\",\n",
    "        \"Refund processed: ${amount} to {method}\",\n",
    "        \"Daily settlement completed: {count} transactions, ${total}\",\n",
    "        \"Payment method added for user {user_id}: {type} ending in {last4}\",\n",
    "    ],\n",
    "    \"inventory-service\": [\n",
    "        \"Stock updated for SKU {sku}: {old_qty} -> {new_qty}\",\n",
    "        \"Inventory reserved for order {order_id}: {quantity} x {sku}\",\n",
    "        \"Warehouse {warehouse_id} sync completed: {count} SKUs updated\",\n",
    "        \"Restock shipment received: {count} units for {sku}\",\n",
    "        \"Inventory audit completed: {matched} matched, {discrepancies} discrepancies\",\n",
    "    ],\n",
    "    \"notification-service\": [\n",
    "        \"Email sent to {email}: {subject}\",\n",
    "        \"Push notification delivered to {device_count} devices\",\n",
    "        \"SMS sent to {phone}: delivery confirmed\",\n",
    "        \"Notification batch processed: {count} messages in {duration}ms\",\n",
    "        \"User {user_id} notification preferences updated\",\n",
    "    ],\n",
    "    \"search-service\": [\n",
    "        \"Search query completed in {duration}ms: {results} results for '{query}'\",\n",
    "        \"Index {index} refreshed, {docs} documents searchable\",\n",
    "        \"Search suggestions generated for '{prefix}': {count} suggestions\",\n",
    "        \"Elasticsearch cluster health GREEN: {nodes} nodes, {shards} shards\",\n",
    "        \"Search analytics aggregated: {queries} queries, {clicks} clicks\",\n",
    "    ],\n",
    "    \"recommendation-engine\": [\n",
    "        \"Recommendations generated for user {user_id}: {count} items in {duration}ms\",\n",
    "        \"Model v{version} deployed successfully to {replicas} replicas\",\n",
    "        \"Feature store updated: {features} features for {users} users\",\n",
    "        \"A/B test {test_id} started: {variants} variants, {traffic}% traffic\",\n",
    "        \"Batch inference completed: {count} users processed\",\n",
    "    ],\n",
    "    \"cache-service\": [\n",
    "        \"Cache hit for key {key}: served in {duration}us\",\n",
    "        \"Cache warmed: {count} keys preloaded\",\n",
    "        \"Redis cluster rebalanced: {slots} slots migrated\",\n",
    "        \"Memory usage nominal: {percent}% of max capacity\",\n",
    "        \"Cache statistics: {hits} hits, {misses} misses, {ratio}% hit rate\",\n",
    "    ],\n",
    "    \"auth-service\": [\n",
    "        \"OAuth login successful: user {user_id} via {provider}\",\n",
    "        \"Access token issued for user {user_id}, expires in {minutes} minutes\",\n",
    "        \"API key created for user {user_id}\",\n",
    "        \"MFA enabled for user {user_id}: {method}\",\n",
    "        \"Security audit: {active} active sessions for user {user_id}\",\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack trace templates for errors\n",
    "stack_traces = [\n",
    "    \"\"\"java.lang.NullPointerException: Cannot invoke method on null object\n",
    "    at com.example.service.UserService.getUser(UserService.java:142)\n",
    "    at com.example.controller.UserController.handleRequest(UserController.java:87)\n",
    "    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:897)\n",
    "    at javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\"\"\",\n",
    "    \n",
    "    \"\"\"java.sql.SQLException: Connection pool exhausted, no available connections\n",
    "    at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:155)\n",
    "    at com.example.repository.OrderRepository.findById(OrderRepository.java:45)\n",
    "    at com.example.service.OrderService.processOrder(OrderService.java:201)\n",
    "    at com.example.controller.OrderController.createOrder(OrderController.java:63)\"\"\",\n",
    "    \n",
    "    \"\"\"redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool\n",
    "    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:84)\n",
    "    at com.example.cache.CacheService.get(CacheService.java:56)\n",
    "    at com.example.service.ProductService.getProduct(ProductService.java:78)\"\"\",\n",
    "    \n",
    "    \"\"\"org.elasticsearch.ElasticsearchTimeoutException: Timeout waiting for search response\n",
    "    at org.elasticsearch.client.RestHighLevelClient.search(RestHighLevelClient.java:1012)\n",
    "    at com.example.search.SearchService.executeSearch(SearchService.java:145)\n",
    "    at com.example.controller.SearchController.search(SearchController.java:52)\"\"\",\n",
    "    \n",
    "    \"\"\"com.stripe.exception.CardException: Your card was declined\n",
    "    at com.stripe.net.LiveStripeResponseGetter.handleError(LiveStripeResponseGetter.java:214)\n",
    "    at com.example.payment.StripePaymentGateway.charge(StripePaymentGateway.java:89)\n",
    "    at com.example.service.PaymentService.processPayment(PaymentService.java:156)\"\"\",\n",
    "    \n",
    "    \"\"\"io.grpc.StatusRuntimeException: UNAVAILABLE: upstream connect error or disconnect/reset before headers\n",
    "    at io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:271)\n",
    "    at com.example.client.InventoryClient.checkStock(InventoryClient.java:67)\n",
    "    at com.example.service.OrderService.validateOrder(OrderService.java:112)\"\"\",\n",
    "    \n",
    "    \"\"\"org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms\n",
    "    at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:999)\n",
    "    at com.example.messaging.EventPublisher.publish(EventPublisher.java:45)\n",
    "    at com.example.service.OrderService.publishOrderEvent(OrderService.java:234)\"\"\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def generate_ip():\n",
    "    return f\"{random.randint(1,255)}.{random.randint(0,255)}.{random.randint(0,255)}.{random.randint(1,254)}\"\n",
    "\n",
    "def generate_user_id():\n",
    "    return f\"user_{random.randint(10000, 99999)}\"\n",
    "\n",
    "def generate_order_id():\n",
    "    return f\"ORD-{random.randint(100000, 999999)}\"\n",
    "\n",
    "def generate_transaction_id():\n",
    "    return f\"txn_{uuid.uuid4().hex[:16]}\"\n",
    "\n",
    "def generate_trace_id():\n",
    "    return uuid.uuid4().hex\n",
    "\n",
    "def generate_span_id():\n",
    "    return uuid.uuid4().hex[:16]\n",
    "\n",
    "def fill_template(template, service_name):\n",
    "    \"\"\"Fill a template with random realistic values\"\"\"\n",
    "    replacements = {\n",
    "        \"{service}\": random.choice([s[\"name\"] for s in services]),\n",
    "        \"{timeout}\": str(random.choice([1000, 2000, 3000, 5000, 10000, 30000])),\n",
    "        \"{ip}\": generate_ip(),\n",
    "        \"{requests}\": str(random.randint(100, 1000)),\n",
    "        \"{window}\": str(random.choice([60, 300, 600])),\n",
    "        \"{reason}\": random.choice([\"connection_refused\", \"timeout\", \"invalid_response\", \"certificate_expired\", \"rate_limited\"]),\n",
    "        \"{size}\": str(random.randint(10, 100)),\n",
    "        \"{status}\": str(random.choice([200, 201, 400, 401, 403, 404, 500, 502, 503, 504])),\n",
    "        \"{message}\": random.choice([\"Internal Server Error\", \"Bad Gateway\", \"Service Unavailable\", \"Gateway Timeout\", \"OK\"]),\n",
    "        \"{user_id}\": generate_user_id(),\n",
    "        \"{waiting}\": str(random.randint(10, 100)),\n",
    "        \"{email}\": f\"user{random.randint(1000,9999)}@example.com\",\n",
    "        \"{minutes}\": str(random.randint(30, 120)),\n",
    "        \"{code}\": str(random.choice([421, 450, 451, 452, 550, 551, 552, 553, 554])),\n",
    "        \"{order_id}\": generate_order_id(),\n",
    "        \"{sku}\": f\"SKU-{random.randint(10000, 99999)}\",\n",
    "        \"{hours}\": str(random.randint(1, 48)),\n",
    "        \"{txn_id}\": generate_transaction_id(),\n",
    "        \"{score}\": str(random.randint(70, 99)),\n",
    "        \"{from_curr}\": random.choice([\"USD\", \"EUR\", \"GBP\"]),\n",
    "        \"{to_curr}\": random.choice([\"JPY\", \"CNY\", \"INR\"]),\n",
    "        \"{gateway}\": random.choice([\"stripe\", \"paypal\", \"braintree\", \"adyen\"]),\n",
    "        \"{error_code}\": random.choice([\"card_declined\", \"insufficient_funds\", \"expired_card\", \"invalid_cvc\"]),\n",
    "        \"{expected}\": str(random.randint(100, 500)),\n",
    "        \"{actual}\": str(random.randint(0, 99)),\n",
    "        \"{warehouse_id}\": f\"WH-{random.choice(['US-EAST', 'US-WEST', 'EU-CENTRAL', 'APAC'])}01\",\n",
    "        \"{quantity}\": str(random.randint(1, 100)),\n",
    "        \"{device_id}\": f\"device_{uuid.uuid4().hex[:12]}\",\n",
    "        \"{provider}\": random.choice([\"twilio\", \"sendgrid\", \"aws_sns\", \"firebase\"]),\n",
    "        \"{count}\": str(random.randint(10, 1000)),\n",
    "        \"{age}\": str(random.randint(60, 3600)),\n",
    "        \"{template}\": random.choice([\"order_confirmation\", \"password_reset\", \"welcome\", \"shipping_update\"]),\n",
    "        \"{var}\": random.choice([\"customer_name\", \"order_total\", \"tracking_number\", \"delivery_date\"]),\n",
    "        \"{shards}\": str(random.randint(1, 10)),\n",
    "        \"{query}\": random.choice([\"laptop gaming\", \"iphone case\", \"running shoes\", \"wireless headphones\"]),\n",
    "        \"{index}\": random.choice([\"products\", \"orders\", \"users\", \"logs\"]),\n",
    "        \"{buckets}\": str(random.randint(10000, 100000)),\n",
    "        \"{doc_id}\": f\"doc_{uuid.uuid4().hex[:8]}\",\n",
    "        \"{percent}\": str(random.randint(10, 50)),\n",
    "        \"{test_id}\": f\"test_{random.randint(100, 999)}\",\n",
    "        \"{node}\": f\"redis-{random.randint(1, 5)}\",\n",
    "        \"{evicted}\": str(random.randint(1000, 10000)),\n",
    "        \"{seconds}\": str(random.randint(1, 60)),\n",
    "        \"{key}\": f\"cache:{random.choice(['user', 'product', 'session', 'config'])}:{random.randint(1000, 9999)}\",\n",
    "        \"{attempts}\": str(random.randint(5, 50)),\n",
    "        \"{error}\": random.choice([\"access_denied\", \"invalid_grant\", \"invalid_client\", \"expired_token\"]),\n",
    "        \"{server}\": f\"ldap.{random.choice(['us', 'eu', 'ap'])}.corp.internal\",\n",
    "        \"{method}\": random.choice([\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"]),\n",
    "        \"{path}\": random.choice([\"/api/v1/users\", \"/api/v1/orders\", \"/api/v1/products\", \"/api/v1/search\", \"/health\"]),\n",
    "        \"{duration}\": str(random.randint(5, 2000)),\n",
    "        \"{fields}\": random.choice([\"email,phone\", \"name\", \"address\", \"preferences\"]),\n",
    "        \"{amount}\": f\"{random.randint(10, 500)}.{random.randint(0, 99):02d}\",\n",
    "        \"{from_status}\": random.choice([\"pending\", \"processing\", \"shipped\"]),\n",
    "        \"{to_status}\": random.choice([\"processing\", \"shipped\", \"delivered\"]),\n",
    "        \"{carrier}\": random.choice([\"fedex\", \"ups\", \"usps\", \"dhl\"]),\n",
    "        \"{tracking}\": f\"{random.choice(['1Z', 'FX', 'DHL'])}{random.randint(1000000000, 9999999999)}\",\n",
    "        \"{city}\": random.choice([\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"London\", \"Paris\", \"Tokyo\"]),\n",
    "        \"{country}\": random.choice([\"USA\", \"UK\", \"France\", \"Germany\", \"Japan\", \"Canada\"]),\n",
    "        \"{old_qty}\": str(random.randint(10, 100)),\n",
    "        \"{new_qty}\": str(random.randint(0, 200)),\n",
    "        \"{matched}\": str(random.randint(900, 1000)),\n",
    "        \"{discrepancies}\": str(random.randint(0, 10)),\n",
    "        \"{subject}\": random.choice([\"Order Confirmation\", \"Shipping Update\", \"Password Reset\", \"Welcome!\"]),\n",
    "        \"{device_count}\": str(random.randint(1, 5)),\n",
    "        \"{phone}\": f\"+1{random.randint(2000000000, 9999999999)}\",\n",
    "        \"{results}\": str(random.randint(10, 10000)),\n",
    "        \"{docs}\": str(random.randint(10000, 1000000)),\n",
    "        \"{prefix}\": random.choice([\"lapt\", \"phon\", \"shoe\", \"head\"]),\n",
    "        \"{nodes}\": str(random.randint(3, 10)),\n",
    "        \"{queries}\": str(random.randint(1000, 100000)),\n",
    "        \"{clicks}\": str(random.randint(100, 10000)),\n",
    "        \"{version}\": f\"{random.randint(1, 5)}.{random.randint(0, 9)}.{random.randint(0, 99)}\",\n",
    "        \"{replicas}\": str(random.randint(2, 10)),\n",
    "        \"{features}\": str(random.randint(50, 200)),\n",
    "        \"{users}\": str(random.randint(10000, 1000000)),\n",
    "        \"{variants}\": str(random.randint(2, 4)),\n",
    "        \"{traffic}\": str(random.randint(5, 50)),\n",
    "        \"{slots}\": str(random.randint(100, 1000)),\n",
    "        \"{hits}\": str(random.randint(10000, 100000)),\n",
    "        \"{misses}\": str(random.randint(100, 1000)),\n",
    "        \"{ratio}\": str(random.randint(90, 99)),\n",
    "        \"{active}\": str(random.randint(1, 10)),\n",
    "        \"{type}\": random.choice([\"visa\", \"mastercard\", \"amex\"]),\n",
    "        \"{last4}\": f\"{random.randint(1000, 9999)}\",\n",
    "        \"{total}\": f\"{random.randint(10000, 100000)}.{random.randint(0, 99):02d}\",\n",
    "    }\n",
    "    \n",
    "    result = template\n",
    "    for placeholder, value in replacements.items():\n",
    "        result = result.replace(placeholder, value)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_log_entry(base_time, service_info):\n",
    "    \"\"\"Generate a single log entry with full Kubernetes metadata\"\"\"\n",
    "    \n",
    "    log_level = random.choices(log_levels, weights=log_level_weights)[0]\n",
    "    service_name = service_info[\"name\"]\n",
    "    \n",
    "    # Generate message based on log level\n",
    "    if log_level in [\"ERROR\", \"FATAL\"]:\n",
    "        templates = error_templates.get(service_name, error_templates[\"api-gateway\"])\n",
    "        message = fill_template(random.choice(templates), service_name)\n",
    "        stack_trace = random.choice(stack_traces) if random.random() < 0.7 else None\n",
    "    elif log_level == \"WARN\":\n",
    "        if random.random() < 0.5:\n",
    "            templates = error_templates.get(service_name, error_templates[\"api-gateway\"])\n",
    "        else:\n",
    "            templates = info_templates.get(service_name, info_templates[\"api-gateway\"])\n",
    "        message = fill_template(random.choice(templates), service_name)\n",
    "        stack_trace = None\n",
    "    else:\n",
    "        templates = info_templates.get(service_name, info_templates[\"api-gateway\"])\n",
    "        message = fill_template(random.choice(templates), service_name)\n",
    "        stack_trace = None\n",
    "    \n",
    "    timestamp = base_time + timedelta(seconds=random.randint(0, 3600), milliseconds=random.randint(0, 999))\n",
    "    trace_id = generate_trace_id()\n",
    "    span_id = generate_span_id()\n",
    "    \n",
    "    log_entry = {\n",
    "        \"@timestamp\": timestamp.isoformat(),\n",
    "        \"log.level\": log_level,\n",
    "        \"message\": message,\n",
    "        \"service.name\": service_name,\n",
    "        # Kubernetes metadata\n",
    "        \"kubernetes.pod.name\": service_info.get(\"k8s.pod.name\", f\"{service_name}-0-xxxxx\"),\n",
    "        \"kubernetes.pod.uid\": service_info.get(\"k8s.pod.uid\", str(uuid.uuid4())),\n",
    "        \"kubernetes.namespace\": service_info.get(\"k8s.namespace\", K8S_NAMESPACE),\n",
    "        \"kubernetes.node.name\": service_info.get(\"k8s.node.name\", \"node-pool-1-abc12\"),\n",
    "        \"kubernetes.deployment.name\": service_info.get(\"k8s.deployment.name\", service_name),\n",
    "        \"kubernetes.replicaset.name\": service_info.get(\"k8s.replicaset.name\", f\"{service_name}-xxxxx\"),\n",
    "        \"container.image.name\": service_info.get(\"container.image.name\", f\"ecommerce/{service_name}:latest\"),\n",
    "        \"container.id\": service_info.get(\"container.id\", f\"docker://{uuid.uuid4().hex}\"),\n",
    "        # Host/cloud info\n",
    "        \"host.name\": service_info.get(\"host.name\", service_info.get(\"host\", \"unknown\")),\n",
    "        \"cloud.availability_zone\": service_info.get(\"cloud.availability_zone\", \"us-east-1a\"),\n",
    "        \"cloud.provider\": \"aws\",\n",
    "        \"cloud.region\": \"us-east-1\",\n",
    "        # Tracing\n",
    "        \"trace.id\": trace_id,\n",
    "        \"span.id\": span_id,\n",
    "        \"process.pid\": random.randint(1, 100),  # Container PIDs are low\n",
    "        \"process.thread.name\": f\"worker-{random.randint(1, 16)}\",\n",
    "    }\n",
    "    \n",
    "    # Add HTTP fields\n",
    "    if service_name in [\"api-gateway\", \"user-service\", \"order-service\", \"search-service\"]:\n",
    "        http_status = random.choices(http_status_codes, weights=http_status_weights)[0]\n",
    "        log_entry[\"http.request.method\"] = random.choice([\"GET\", \"POST\", \"PUT\", \"DELETE\"])\n",
    "        log_entry[\"http.response.status_code\"] = http_status\n",
    "        log_entry[\"http.request.duration_ms\"] = random.randint(1, 5000)\n",
    "        log_entry[\"client.ip\"] = generate_ip()\n",
    "        log_entry[\"user_agent.original\"] = random.choice(user_agents)\n",
    "    \n",
    "    if stack_trace:\n",
    "        log_entry[\"error.stack_trace\"] = stack_trace\n",
    "        log_entry[\"error.type\"] = stack_trace.split(\":\")[0]\n",
    "    \n",
    "    return log_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all indices with appropriate mappings\n",
    "LOGS_INDEX = \"application-logs\"\n",
    "METRICS_INDEX = \"system-metrics\"\n",
    "K8S_EVENTS_INDEX = \"kubernetes-events\"\n",
    "TRACES_INDEX = \"distributed-traces\"\n",
    "\n",
    "logs_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"@timestamp\": {\"type\": \"date\"},\n",
    "            \"log.level\": {\"type\": \"keyword\"},\n",
    "            \"message\": {\"type\": \"text\", \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 512}}},\n",
    "            \"service.name\": {\"type\": \"keyword\"},\n",
    "            # Kubernetes fields\n",
    "            \"kubernetes.pod.name\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.pod.uid\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.namespace\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.node.name\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.deployment.name\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.replicaset.name\": {\"type\": \"keyword\"},\n",
    "            \"container.image.name\": {\"type\": \"keyword\"},\n",
    "            \"container.id\": {\"type\": \"keyword\"},\n",
    "            # Host/cloud\n",
    "            \"host.name\": {\"type\": \"keyword\"},\n",
    "            \"cloud.availability_zone\": {\"type\": \"keyword\"},\n",
    "            \"cloud.provider\": {\"type\": \"keyword\"},\n",
    "            \"cloud.region\": {\"type\": \"keyword\"},\n",
    "            # Tracing\n",
    "            \"trace.id\": {\"type\": \"keyword\"},\n",
    "            \"span.id\": {\"type\": \"keyword\"},\n",
    "            \"process.pid\": {\"type\": \"integer\"},\n",
    "            \"process.thread.name\": {\"type\": \"keyword\"},\n",
    "            # HTTP\n",
    "            \"http.request.method\": {\"type\": \"keyword\"},\n",
    "            \"http.response.status_code\": {\"type\": \"integer\"},\n",
    "            \"http.request.duration_ms\": {\"type\": \"integer\"},\n",
    "            \"client.ip\": {\"type\": \"ip\"},\n",
    "            \"user_agent.original\": {\"type\": \"text\"},\n",
    "            # Errors\n",
    "            \"error.stack_trace\": {\"type\": \"text\"},\n",
    "            \"error.type\": {\"type\": \"keyword\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "metrics_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"@timestamp\": {\"type\": \"date\"},\n",
    "            \"kubernetes.pod.name\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.namespace\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.node.name\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.deployment.name\": {\"type\": \"keyword\"},\n",
    "            \"service.name\": {\"type\": \"keyword\"},\n",
    "            \"container.id\": {\"type\": \"keyword\"},\n",
    "            # CPU metrics\n",
    "            \"system.cpu.total.pct\": {\"type\": \"float\"},\n",
    "            \"system.cpu.user.pct\": {\"type\": \"float\"},\n",
    "            \"system.cpu.system.pct\": {\"type\": \"float\"},\n",
    "            \"kubernetes.pod.cpu.usage.limit.pct\": {\"type\": \"float\"},\n",
    "            # Memory metrics\n",
    "            \"system.memory.used.bytes\": {\"type\": \"long\"},\n",
    "            \"system.memory.total.bytes\": {\"type\": \"long\"},\n",
    "            \"system.memory.used.pct\": {\"type\": \"float\"},\n",
    "            \"kubernetes.pod.memory.usage.bytes\": {\"type\": \"long\"},\n",
    "            \"kubernetes.pod.memory.limit.bytes\": {\"type\": \"long\"},\n",
    "            # Network\n",
    "            \"system.network.in.bytes\": {\"type\": \"long\"},\n",
    "            \"system.network.out.bytes\": {\"type\": \"long\"},\n",
    "            \"system.network.in.packets\": {\"type\": \"long\"},\n",
    "            \"system.network.out.packets\": {\"type\": \"long\"},\n",
    "            # Disk\n",
    "            \"system.diskio.read.bytes\": {\"type\": \"long\"},\n",
    "            \"system.diskio.write.bytes\": {\"type\": \"long\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "k8s_events_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"@timestamp\": {\"type\": \"date\"},\n",
    "            \"kubernetes.event.type\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.event.reason\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.event.message\": {\"type\": \"text\"},\n",
    "            \"kubernetes.event.count\": {\"type\": \"integer\"},\n",
    "            \"kubernetes.event.first_timestamp\": {\"type\": \"date\"},\n",
    "            \"kubernetes.event.last_timestamp\": {\"type\": \"date\"},\n",
    "            \"kubernetes.pod.name\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.namespace\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.node.name\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.deployment.name\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.event.involved_object.kind\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.event.involved_object.name\": {\"type\": \"keyword\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "traces_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"@timestamp\": {\"type\": \"date\"},\n",
    "            \"trace.id\": {\"type\": \"keyword\"},\n",
    "            \"span.id\": {\"type\": \"keyword\"},\n",
    "            \"parent.span.id\": {\"type\": \"keyword\"},\n",
    "            \"span.name\": {\"type\": \"keyword\"},\n",
    "            \"span.kind\": {\"type\": \"keyword\"},\n",
    "            \"service.name\": {\"type\": \"keyword\"},\n",
    "            \"kubernetes.pod.name\": {\"type\": \"keyword\"},\n",
    "            \"span.duration.us\": {\"type\": \"long\"},\n",
    "            \"span.status.code\": {\"type\": \"keyword\"},\n",
    "            \"http.method\": {\"type\": \"keyword\"},\n",
    "            \"http.url\": {\"type\": \"keyword\"},\n",
    "            \"http.status_code\": {\"type\": \"integer\"},\n",
    "            \"db.type\": {\"type\": \"keyword\"},\n",
    "            \"db.statement\": {\"type\": \"text\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create all indices\n",
    "for idx_name, mapping in [(LOGS_INDEX, logs_mapping), (METRICS_INDEX, metrics_mapping), \n",
    "                           (K8S_EVENTS_INDEX, k8s_events_mapping), (TRACES_INDEX, traces_mapping)]:\n",
    "    if es.indices.exists(index=idx_name):\n",
    "        es.indices.delete(index=idx_name)\n",
    "        print(f\"Deleted existing index: {idx_name}\")\n",
    "    es.indices.create(index=idx_name, body=mapping)\n",
    "    print(f\"Created index: {idx_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate logs for the past 24 hours with realistic incident patterns\n",
    "def generate_and_index_logs(num_logs=5000):\n",
    "    print(f\"Generating {num_logs} log entries...\")\n",
    "    \n",
    "    actions = []\n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(hours=24)\n",
    "    \n",
    "    # Define incident windows (simulating real outages)\n",
    "    incidents = [\n",
    "        {\"start\": 2, \"end\": 3, \"service\": \"recommendation-engine\", \"type\": \"oom\"},\n",
    "        {\"start\": 6, \"end\": 7, \"service\": \"order-service\", \"type\": \"db_pool\"},\n",
    "        {\"start\": 14, \"end\": 15, \"service\": \"payment-service\", \"type\": \"timeout\"},\n",
    "        {\"start\": 20, \"end\": 21, \"service\": \"inventory-service\", \"type\": \"network\"},\n",
    "    ]\n",
    "    \n",
    "    for i in range(num_logs):\n",
    "        hours_ago = random.uniform(0, 24)\n",
    "        base_time = end_time - timedelta(hours=hours_ago)\n",
    "        \n",
    "        # Check if we're in an incident window - increase error rate\n",
    "        in_incident = False\n",
    "        incident_service = None\n",
    "        for inc in incidents:\n",
    "            if inc[\"start\"] <= (24 - hours_ago) <= inc[\"end\"]:\n",
    "                in_incident = True\n",
    "                incident_service = inc[\"service\"]\n",
    "                break\n",
    "        \n",
    "        # Bias service selection during incidents\n",
    "        if in_incident and random.random() < 0.4:\n",
    "            service_info = random.choice([s for s in services if s[\"name\"] == incident_service])\n",
    "        else:\n",
    "            service_info = random.choice(services)\n",
    "        \n",
    "        log_entry = generate_log_entry(base_time, service_info)\n",
    "        \n",
    "        # Increase error rate during incidents\n",
    "        if in_incident and service_info[\"name\"] == incident_service:\n",
    "            if random.random() < 0.6:\n",
    "                log_entry[\"log.level\"] = random.choice([\"ERROR\", \"FATAL\", \"WARN\"])\n",
    "        \n",
    "        actions.append({\"_index\": LOGS_INDEX, \"_source\": log_entry})\n",
    "        \n",
    "        if len(actions) >= 1000:\n",
    "            helpers.bulk(es, actions)\n",
    "            print(f\"Indexed {i + 1} logs...\")\n",
    "            actions = []\n",
    "    \n",
    "    if actions:\n",
    "        helpers.bulk(es, actions)\n",
    "    \n",
    "    print(f\"Successfully indexed {num_logs} log entries!\")\n",
    "\n",
    "generate_and_index_logs(5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate system metrics for pods\n",
    "def generate_metrics(num_metrics=3000):\n",
    "    print(f\"Generating {num_metrics} metric entries...\")\n",
    "    \n",
    "    actions = []\n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    # Memory leak simulation for recommendation-engine (hours 2-3)\n",
    "    memory_leak_pods = [s for s in services if s[\"name\"] == \"recommendation-engine\"]\n",
    "    \n",
    "    for i in range(num_metrics):\n",
    "        hours_ago = random.uniform(0, 24)\n",
    "        timestamp = end_time - timedelta(hours=hours_ago)\n",
    "        \n",
    "        service_info = random.choice(services)\n",
    "        node = next((n for n in K8S_NODES if n[\"name\"] == service_info.get(\"k8s.node.name\")), K8S_NODES[0])\n",
    "        \n",
    "        # Base metrics\n",
    "        cpu_base = random.uniform(0.1, 0.4)\n",
    "        memory_base = random.uniform(0.3, 0.6)\n",
    "        \n",
    "        # Simulate memory leak in recommendation-engine (hours 2-3)\n",
    "        if service_info[\"name\"] == \"recommendation-engine\" and 2 <= (24 - hours_ago) <= 3:\n",
    "            progress = ((24 - hours_ago) - 2) / 1.0  # 0 to 1 over the hour\n",
    "            memory_base = 0.6 + (progress * 0.35)  # Ramp up to 95%\n",
    "            cpu_base = 0.3 + (progress * 0.5)  # CPU spikes too\n",
    "        \n",
    "        # High CPU during order-service DB issue (hours 6-7)\n",
    "        if service_info[\"name\"] == \"order-service\" and 6 <= (24 - hours_ago) <= 7:\n",
    "            cpu_base = random.uniform(0.7, 0.95)\n",
    "        \n",
    "        memory_limit_bytes = 2 * 1024 * 1024 * 1024  # 2GB\n",
    "        memory_used = int(memory_limit_bytes * memory_base)\n",
    "        \n",
    "        metric = {\n",
    "            \"@timestamp\": timestamp.isoformat(),\n",
    "            \"kubernetes.pod.name\": service_info.get(\"k8s.pod.name\"),\n",
    "            \"kubernetes.namespace\": K8S_NAMESPACE,\n",
    "            \"kubernetes.node.name\": service_info.get(\"k8s.node.name\"),\n",
    "            \"kubernetes.deployment.name\": service_info[\"name\"],\n",
    "            \"service.name\": service_info[\"name\"],\n",
    "            \"container.id\": service_info.get(\"container.id\"),\n",
    "            # CPU\n",
    "            \"system.cpu.total.pct\": round(cpu_base, 3),\n",
    "            \"system.cpu.user.pct\": round(cpu_base * 0.7, 3),\n",
    "            \"system.cpu.system.pct\": round(cpu_base * 0.3, 3),\n",
    "            \"kubernetes.pod.cpu.usage.limit.pct\": round(cpu_base * 100, 1),\n",
    "            # Memory\n",
    "            \"system.memory.used.bytes\": memory_used,\n",
    "            \"system.memory.total.bytes\": memory_limit_bytes,\n",
    "            \"system.memory.used.pct\": round(memory_base, 3),\n",
    "            \"kubernetes.pod.memory.usage.bytes\": memory_used,\n",
    "            \"kubernetes.pod.memory.limit.bytes\": memory_limit_bytes,\n",
    "            # Network\n",
    "            \"system.network.in.bytes\": random.randint(100000, 10000000),\n",
    "            \"system.network.out.bytes\": random.randint(100000, 10000000),\n",
    "            \"system.network.in.packets\": random.randint(100, 10000),\n",
    "            \"system.network.out.packets\": random.randint(100, 10000),\n",
    "            # Disk\n",
    "            \"system.diskio.read.bytes\": random.randint(10000, 1000000),\n",
    "            \"system.diskio.write.bytes\": random.randint(10000, 1000000),\n",
    "        }\n",
    "        \n",
    "        actions.append({\"_index\": METRICS_INDEX, \"_source\": metric})\n",
    "        \n",
    "        if len(actions) >= 500:\n",
    "            helpers.bulk(es, actions)\n",
    "            actions = []\n",
    "    \n",
    "    if actions:\n",
    "        helpers.bulk(es, actions)\n",
    "    \n",
    "    print(f\"Successfully indexed {num_metrics} metrics!\")\n",
    "\n",
    "generate_metrics(3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Kubernetes events\n",
    "def generate_k8s_events():\n",
    "    print(\"Generating Kubernetes events...\")\n",
    "    \n",
    "    actions = []\n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    # Normal events\n",
    "    normal_events = [\n",
    "        {\"reason\": \"Scheduled\", \"message\": \"Successfully assigned {ns}/{pod} to {node}\", \"type\": \"Normal\"},\n",
    "        {\"reason\": \"Pulled\", \"message\": \"Container image \\\"{image}\\\" already present on machine\", \"type\": \"Normal\"},\n",
    "        {\"reason\": \"Created\", \"message\": \"Created container {container}\", \"type\": \"Normal\"},\n",
    "        {\"reason\": \"Started\", \"message\": \"Started container {container}\", \"type\": \"Normal\"},\n",
    "        {\"reason\": \"SuccessfulCreate\", \"message\": \"Created pod: {pod}\", \"type\": \"Normal\"},\n",
    "        {\"reason\": \"ScalingReplicaSet\", \"message\": \"Scaled up replica set {rs} to {count}\", \"type\": \"Normal\"},\n",
    "    ]\n",
    "    \n",
    "    # Warning events (correlated with incidents)\n",
    "    warning_events = [\n",
    "        {\"reason\": \"OOMKilled\", \"message\": \"Container {container} was OOM killed\", \"type\": \"Warning\", \"service\": \"recommendation-engine\", \"hour\": 2.5},\n",
    "        {\"reason\": \"OOMKilled\", \"message\": \"Container {container} exceeded memory limit\", \"type\": \"Warning\", \"service\": \"recommendation-engine\", \"hour\": 2.8},\n",
    "        {\"reason\": \"BackOff\", \"message\": \"Back-off restarting failed container\", \"type\": \"Warning\", \"service\": \"recommendation-engine\", \"hour\": 2.9},\n",
    "        {\"reason\": \"Unhealthy\", \"message\": \"Readiness probe failed: connection refused\", \"type\": \"Warning\", \"service\": \"order-service\", \"hour\": 6.2},\n",
    "        {\"reason\": \"Unhealthy\", \"message\": \"Liveness probe failed: HTTP probe failed with statuscode: 503\", \"type\": \"Warning\", \"service\": \"order-service\", \"hour\": 6.5},\n",
    "        {\"reason\": \"FailedScheduling\", \"message\": \"0/5 nodes are available: insufficient memory\", \"type\": \"Warning\", \"service\": \"recommendation-engine\", \"hour\": 3.0},\n",
    "        {\"reason\": \"NetworkNotReady\", \"message\": \"network is not ready: container runtime network not ready\", \"type\": \"Warning\", \"service\": \"inventory-service\", \"hour\": 20.2},\n",
    "    ]\n",
    "    \n",
    "    # Generate normal events throughout the day\n",
    "    for _ in range(100):\n",
    "        hours_ago = random.uniform(0, 24)\n",
    "        timestamp = end_time - timedelta(hours=hours_ago)\n",
    "        service_info = random.choice(services)\n",
    "        event_template = random.choice(normal_events)\n",
    "        \n",
    "        event = {\n",
    "            \"@timestamp\": timestamp.isoformat(),\n",
    "            \"kubernetes.event.type\": event_template[\"type\"],\n",
    "            \"kubernetes.event.reason\": event_template[\"reason\"],\n",
    "            \"kubernetes.event.message\": event_template[\"message\"].format(\n",
    "                ns=K8S_NAMESPACE,\n",
    "                pod=service_info.get(\"k8s.pod.name\"),\n",
    "                node=service_info.get(\"k8s.node.name\"),\n",
    "                image=service_info.get(\"container.image.name\"),\n",
    "                container=service_info[\"name\"],\n",
    "                rs=service_info.get(\"k8s.replicaset.name\"),\n",
    "                count=random.randint(1, 3)\n",
    "            ),\n",
    "            \"kubernetes.event.count\": 1,\n",
    "            \"kubernetes.event.first_timestamp\": timestamp.isoformat(),\n",
    "            \"kubernetes.event.last_timestamp\": timestamp.isoformat(),\n",
    "            \"kubernetes.pod.name\": service_info.get(\"k8s.pod.name\"),\n",
    "            \"kubernetes.namespace\": K8S_NAMESPACE,\n",
    "            \"kubernetes.node.name\": service_info.get(\"k8s.node.name\"),\n",
    "            \"kubernetes.deployment.name\": service_info[\"name\"],\n",
    "            \"kubernetes.event.involved_object.kind\": \"Pod\",\n",
    "            \"kubernetes.event.involved_object.name\": service_info.get(\"k8s.pod.name\"),\n",
    "        }\n",
    "        actions.append({\"_index\": K8S_EVENTS_INDEX, \"_source\": event})\n",
    "    \n",
    "    # Generate warning events at specific incident times\n",
    "    for event_template in warning_events:\n",
    "        target_service = event_template.get(\"service\")\n",
    "        matching_pods = [s for s in services if s[\"name\"] == target_service]\n",
    "        \n",
    "        for pod in matching_pods:\n",
    "            timestamp = end_time - timedelta(hours=(24 - event_template[\"hour\"]))\n",
    "            event = {\n",
    "                \"@timestamp\": timestamp.isoformat(),\n",
    "                \"kubernetes.event.type\": event_template[\"type\"],\n",
    "                \"kubernetes.event.reason\": event_template[\"reason\"],\n",
    "                \"kubernetes.event.message\": event_template[\"message\"].format(container=target_service),\n",
    "                \"kubernetes.event.count\": random.randint(1, 5),\n",
    "                \"kubernetes.event.first_timestamp\": timestamp.isoformat(),\n",
    "                \"kubernetes.event.last_timestamp\": (timestamp + timedelta(minutes=random.randint(1, 30))).isoformat(),\n",
    "                \"kubernetes.pod.name\": pod.get(\"k8s.pod.name\"),\n",
    "                \"kubernetes.namespace\": K8S_NAMESPACE,\n",
    "                \"kubernetes.node.name\": pod.get(\"k8s.node.name\"),\n",
    "                \"kubernetes.deployment.name\": target_service,\n",
    "                \"kubernetes.event.involved_object.kind\": \"Pod\",\n",
    "                \"kubernetes.event.involved_object.name\": pod.get(\"k8s.pod.name\"),\n",
    "            }\n",
    "            actions.append({\"_index\": K8S_EVENTS_INDEX, \"_source\": event})\n",
    "    \n",
    "    helpers.bulk(es, actions)\n",
    "    print(f\"Successfully indexed {len(actions)} Kubernetes events!\")\n",
    "\n",
    "generate_k8s_events()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate distributed traces (request flows through services)\n",
    "def generate_traces(num_traces=500):\n",
    "    print(f\"Generating {num_traces} distributed traces...\")\n",
    "    \n",
    "    actions = []\n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    # Define typical request flows\n",
    "    flows = [\n",
    "        [\"api-gateway\", \"user-service\", \"auth-service\"],  # Login\n",
    "        [\"api-gateway\", \"order-service\", \"payment-service\", \"inventory-service\", \"notification-service\"],  # Checkout\n",
    "        [\"api-gateway\", \"search-service\", \"recommendation-engine\"],  # Browse\n",
    "        [\"api-gateway\", \"user-service\", \"order-service\"],  # Order history\n",
    "        [\"api-gateway\", \"inventory-service\", \"cache-service\"],  # Stock check\n",
    "    ]\n",
    "    \n",
    "    endpoints = {\n",
    "        \"api-gateway\": [\"/api/v1/login\", \"/api/v1/checkout\", \"/api/v1/search\", \"/api/v1/orders\", \"/api/v1/products\"],\n",
    "        \"user-service\": [\"/users/profile\", \"/users/auth\", \"/users/preferences\"],\n",
    "        \"auth-service\": [\"/auth/token\", \"/auth/verify\", \"/auth/refresh\"],\n",
    "        \"order-service\": [\"/orders/create\", \"/orders/history\", \"/orders/status\"],\n",
    "        \"payment-service\": [\"/payments/authorize\", \"/payments/capture\", \"/payments/refund\"],\n",
    "        \"inventory-service\": [\"/inventory/check\", \"/inventory/reserve\", \"/inventory/release\"],\n",
    "        \"search-service\": [\"/search/products\", \"/search/suggest\"],\n",
    "        \"recommendation-engine\": [\"/recommend/similar\", \"/recommend/personalized\"],\n",
    "        \"notification-service\": [\"/notify/email\", \"/notify/push\"],\n",
    "        \"cache-service\": [\"/cache/get\", \"/cache/set\"],\n",
    "    }\n",
    "    \n",
    "    for _ in range(num_traces):\n",
    "        hours_ago = random.uniform(0, 24)\n",
    "        base_time = end_time - timedelta(hours=hours_ago)\n",
    "        \n",
    "        flow = random.choice(flows)\n",
    "        trace_id = generate_trace_id()\n",
    "        parent_span_id = None\n",
    "        \n",
    "        # Check if this trace is during an incident\n",
    "        is_error_trace = False\n",
    "        for inc_start, inc_end, inc_service in [(2, 3, \"recommendation-engine\"), (6, 7, \"order-service\"), \n",
    "                                                  (14, 15, \"payment-service\"), (20, 21, \"inventory-service\")]:\n",
    "            if inc_start <= (24 - hours_ago) <= inc_end and inc_service in flow:\n",
    "                is_error_trace = random.random() < 0.5\n",
    "                break\n",
    "        \n",
    "        span_time = base_time\n",
    "        for i, service_name in enumerate(flow):\n",
    "            service_pods = [s for s in services if s[\"name\"] == service_name]\n",
    "            if not service_pods:\n",
    "                continue\n",
    "            pod = random.choice(service_pods)\n",
    "            \n",
    "            span_id = generate_span_id()\n",
    "            duration_us = random.randint(1000, 50000)  # 1-50ms\n",
    "            \n",
    "            # Increase latency for error traces\n",
    "            if is_error_trace and i > 0:\n",
    "                duration_us = random.randint(100000, 500000)  # 100-500ms (slow)\n",
    "            \n",
    "            status_code = 200\n",
    "            if is_error_trace and i == len(flow) - 1:\n",
    "                status_code = random.choice([500, 502, 503, 504])\n",
    "            \n",
    "            span = {\n",
    "                \"@timestamp\": span_time.isoformat(),\n",
    "                \"trace.id\": trace_id,\n",
    "                \"span.id\": span_id,\n",
    "                \"parent.span.id\": parent_span_id,\n",
    "                \"span.name\": random.choice(endpoints.get(service_name, [\"/unknown\"])),\n",
    "                \"span.kind\": \"SERVER\" if i > 0 else \"CLIENT\",\n",
    "                \"service.name\": service_name,\n",
    "                \"kubernetes.pod.name\": pod.get(\"k8s.pod.name\"),\n",
    "                \"span.duration.us\": duration_us,\n",
    "                \"span.status.code\": \"ERROR\" if status_code >= 400 else \"OK\",\n",
    "                \"http.method\": random.choice([\"GET\", \"POST\"]),\n",
    "                \"http.url\": f\"http://{service_name}:8080{random.choice(endpoints.get(service_name, ['/']))}\",\n",
    "                \"http.status_code\": status_code,\n",
    "            }\n",
    "            \n",
    "            # Add DB span for data services\n",
    "            if service_name in [\"user-service\", \"order-service\", \"inventory-service\"]:\n",
    "                span[\"db.type\"] = \"postgresql\"\n",
    "                span[\"db.statement\"] = f\"SELECT * FROM {service_name.replace('-service', 's')} WHERE id = ?\"\n",
    "            \n",
    "            actions.append({\"_index\": TRACES_INDEX, \"_source\": span})\n",
    "            \n",
    "            parent_span_id = span_id\n",
    "            span_time = span_time + timedelta(microseconds=duration_us)\n",
    "    \n",
    "    helpers.bulk(es, actions)\n",
    "    print(f\"Successfully indexed {len(actions)} trace spans!\")\n",
    "\n",
    "generate_traces(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all data\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA GENERATION COMPLETE - SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx in [LOGS_INDEX, METRICS_INDEX, K8S_EVENTS_INDEX, TRACES_INDEX]:\n",
    "    es.indices.refresh(index=idx)\n",
    "    count = es.count(index=idx)[\"count\"]\n",
    "    print(f\"\\n{idx}: {count} documents\")\n",
    "\n",
    "# Log distribution\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"APPLICATION LOGS DISTRIBUTION:\")\n",
    "agg_result = es.search(\n",
    "    index=LOGS_INDEX, size=0,\n",
    "    body={\"aggs\": {\"by_level\": {\"terms\": {\"field\": \"log.level\"}}, \n",
    "                   \"by_service\": {\"terms\": {\"field\": \"service.name\", \"size\": 15}}}}\n",
    ")\n",
    "print(\"\\nBy log level:\")\n",
    "for bucket in agg_result[\"aggregations\"][\"by_level\"][\"buckets\"]:\n",
    "    print(f\"  {bucket['key']}: {bucket['doc_count']}\")\n",
    "\n",
    "print(\"\\nBy service:\")\n",
    "for bucket in agg_result[\"aggregations\"][\"by_service\"][\"buckets\"]:\n",
    "    print(f\"  {bucket['key']}: {bucket['doc_count']}\")\n",
    "\n",
    "# K8s events\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"KUBERNETES EVENTS:\")\n",
    "k8s_agg = es.search(\n",
    "    index=K8S_EVENTS_INDEX, size=0,\n",
    "    body={\"aggs\": {\"by_reason\": {\"terms\": {\"field\": \"kubernetes.event.reason\"}}}}\n",
    ")\n",
    "for bucket in k8s_agg[\"aggregations\"][\"by_reason\"][\"buckets\"]:\n",
    "    print(f\"  {bucket['key']}: {bucket['doc_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample data from each index\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE DATA FOR ELASTIC-SCRIPT ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Recent errors with K8s context\n",
    "print(\"\\n📋 RECENT ERROR LOGS (with Kubernetes context):\")\n",
    "error_logs = es.search(\n",
    "    index=LOGS_INDEX, size=3,\n",
    "    body={\"query\": {\"terms\": {\"log.level\": [\"ERROR\", \"FATAL\"]}}, \"sort\": [{\"@timestamp\": \"desc\"}]}\n",
    ")\n",
    "for hit in error_logs[\"hits\"][\"hits\"]:\n",
    "    s = hit[\"_source\"]\n",
    "    print(f\"\\n  [{s['log.level']}] {s['service.name']}\")\n",
    "    print(f\"    Pod: {s.get('kubernetes.pod.name', 'N/A')}\")\n",
    "    print(f\"    Node: {s.get('kubernetes.node.name', 'N/A')}\")\n",
    "    print(f\"    Message: {s['message'][:80]}...\")\n",
    "\n",
    "# K8s warning events\n",
    "print(\"\\n\\n⚠️ KUBERNETES WARNING EVENTS:\")\n",
    "k8s_warnings = es.search(\n",
    "    index=K8S_EVENTS_INDEX, size=3,\n",
    "    body={\"query\": {\"term\": {\"kubernetes.event.type\": \"Warning\"}}, \"sort\": [{\"@timestamp\": \"desc\"}]}\n",
    ")\n",
    "for hit in k8s_warnings[\"hits\"][\"hits\"]:\n",
    "    s = hit[\"_source\"]\n",
    "    print(f\"\\n  [{s['kubernetes.event.reason']}] {s.get('kubernetes.deployment.name', 'N/A')}\")\n",
    "    print(f\"    {s['kubernetes.event.message']}\")\n",
    "\n",
    "# High memory pods\n",
    "print(\"\\n\\n📊 PODS WITH HIGH MEMORY USAGE:\")\n",
    "high_mem = es.search(\n",
    "    index=METRICS_INDEX, size=3,\n",
    "    body={\"query\": {\"range\": {\"system.memory.used.pct\": {\"gte\": 0.7}}}, \"sort\": [{\"system.memory.used.pct\": \"desc\"}]}\n",
    ")\n",
    "for hit in high_mem[\"hits\"][\"hits\"]:\n",
    "    s = hit[\"_source\"]\n",
    "    print(f\"  {s.get('kubernetes.pod.name', 'N/A')}: {s['system.memory.used.pct']*100:.1f}% memory\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"AVAILABLE INDICES FOR ELASTIC-SCRIPT:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "• application-logs  - Logs with K8s metadata (pod, node, namespace)\n",
    "• system-metrics    - CPU, memory, network metrics per pod\n",
    "• kubernetes-events - K8s events (OOMKilled, Unhealthy, BackOff, etc.)  \n",
    "• distributed-traces - Request traces spanning multiple services\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
