{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observability Logs Data Generator\n",
    "\n",
    "This notebook generates realistic application logs, error logs, and system metrics for testing elastic-script's LLM integration capabilities.\n",
    "\n",
    "**Use Cases for LLM Analysis:**\n",
    "- Summarize error patterns across services\n",
    "- Classify log severity and impact\n",
    "- Extract structured information from error messages\n",
    "- Identify root causes from stack traces\n",
    "- Generate incident reports from log data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "from elasticsearch import Elasticsearch, helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'scheme': 'http'}])\n",
    "\n",
    "# Verify connection\n",
    "if es.ping():\n",
    "    print(\"Connected to Elasticsearch!\")\n",
    "else:\n",
    "    raise Exception(\"Could not connect to Elasticsearch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Services and components in our fictional microservices architecture\n",
    "services = [\n",
    "    {\"name\": \"api-gateway\", \"host\": \"gateway-prod-01\", \"env\": \"production\"},\n",
    "    {\"name\": \"api-gateway\", \"host\": \"gateway-prod-02\", \"env\": \"production\"},\n",
    "    {\"name\": \"user-service\", \"host\": \"user-prod-01\", \"env\": \"production\"},\n",
    "    {\"name\": \"user-service\", \"host\": \"user-prod-02\", \"env\": \"production\"},\n",
    "    {\"name\": \"order-service\", \"host\": \"order-prod-01\", \"env\": \"production\"},\n",
    "    {\"name\": \"order-service\", \"host\": \"order-prod-02\", \"env\": \"production\"},\n",
    "    {\"name\": \"payment-service\", \"host\": \"payment-prod-01\", \"env\": \"production\"},\n",
    "    {\"name\": \"inventory-service\", \"host\": \"inventory-prod-01\", \"env\": \"production\"},\n",
    "    {\"name\": \"notification-service\", \"host\": \"notif-prod-01\", \"env\": \"production\"},\n",
    "    {\"name\": \"search-service\", \"host\": \"search-prod-01\", \"env\": \"production\"},\n",
    "    {\"name\": \"recommendation-engine\", \"host\": \"rec-prod-01\", \"env\": \"production\"},\n",
    "    {\"name\": \"cache-service\", \"host\": \"cache-prod-01\", \"env\": \"production\"},\n",
    "    {\"name\": \"auth-service\", \"host\": \"auth-prod-01\", \"env\": \"production\"},\n",
    "]\n",
    "\n",
    "log_levels = [\"DEBUG\", \"INFO\", \"WARN\", \"ERROR\", \"FATAL\"]\n",
    "log_level_weights = [10, 60, 20, 8, 2]  # INFO is most common, FATAL is rare\n",
    "\n",
    "# HTTP status codes and their weights\n",
    "http_status_codes = [200, 201, 204, 301, 302, 400, 401, 403, 404, 408, 429, 500, 502, 503, 504]\n",
    "http_status_weights = [50, 10, 5, 2, 2, 5, 3, 2, 8, 2, 3, 4, 1, 2, 1]\n",
    "\n",
    "# User agents\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15\",\n",
    "    \"Mozilla/5.0 (Linux; Android 14) AppleWebKit/537.36 Chrome/120.0.0.0 Mobile\",\n",
    "    \"PostmanRuntime/7.35.0\",\n",
    "    \"python-requests/2.31.0\",\n",
    "    \"curl/8.4.0\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error message templates by service - realistic production errors\n",
    "error_templates = {\n",
    "    \"api-gateway\": [\n",
    "        \"Connection timeout to upstream service {service} after {timeout}ms\",\n",
    "        \"Rate limit exceeded for client IP {ip} - {requests} requests in {window}s\",\n",
    "        \"Circuit breaker OPEN for service {service}, failing fast\",\n",
    "        \"SSL handshake failed with upstream: {reason}\",\n",
    "        \"Request body too large: {size}MB exceeds limit of 10MB\",\n",
    "        \"Invalid JWT token: {reason}\",\n",
    "        \"Upstream service {service} returned {status}: {message}\",\n",
    "    ],\n",
    "    \"user-service\": [\n",
    "        \"Failed to authenticate user {user_id}: {reason}\",\n",
    "        \"Database connection pool exhausted, {waiting} requests waiting\",\n",
    "        \"User {user_id} not found in database\",\n",
    "        \"Password hash verification failed for user {user_id}\",\n",
    "        \"Email validation failed for {email}: {reason}\",\n",
    "        \"Session expired for user {user_id}, last activity {minutes} minutes ago\",\n",
    "        \"Failed to send verification email to {email}: SMTP error {code}\",\n",
    "    ],\n",
    "    \"order-service\": [\n",
    "        \"Order {order_id} processing failed: insufficient inventory for SKU {sku}\",\n",
    "        \"Payment authorization failed for order {order_id}: {reason}\",\n",
    "        \"Order {order_id} stuck in {status} state for {hours} hours\",\n",
    "        \"Failed to calculate shipping for order {order_id}: invalid address\",\n",
    "        \"Duplicate order detected: {order_id} matches existing order\",\n",
    "        \"Order cancellation failed: order {order_id} already shipped\",\n",
    "        \"Tax calculation service timeout for order {order_id}\",\n",
    "    ],\n",
    "    \"payment-service\": [\n",
    "        \"Payment gateway {gateway} returned error: {error_code} - {message}\",\n",
    "        \"Card validation failed for transaction {txn_id}: {reason}\",\n",
    "        \"Refund request failed: original transaction not found\",\n",
    "        \"3DS authentication required but not provided for transaction {txn_id}\",\n",
    "        \"Payment timeout: transaction {txn_id} did not complete in {timeout}s\",\n",
    "        \"Fraud detection triggered for transaction {txn_id}: risk score {score}\",\n",
    "        \"Currency conversion failed: {from_curr} to {to_curr} rate unavailable\",\n",
    "    ],\n",
    "    \"inventory-service\": [\n",
    "        \"Stock level mismatch for SKU {sku}: expected {expected}, actual {actual}\",\n",
    "        \"Warehouse {warehouse_id} sync failed: connection refused\",\n",
    "        \"Reserved inventory expired for order {order_id}, releasing {quantity} units\",\n",
    "        \"Low stock alert: SKU {sku} has only {quantity} units remaining\",\n",
    "        \"Failed to update inventory: optimistic locking conflict for SKU {sku}\",\n",
    "    ],\n",
    "    \"notification-service\": [\n",
    "        \"Push notification failed for device {device_id}: token expired\",\n",
    "        \"Email delivery failed to {email}: bounced with code {code}\",\n",
    "        \"SMS gateway error: {provider} returned {error_code}\",\n",
    "        \"Notification queue backlog: {count} messages pending, oldest {age}s\",\n",
    "        \"Template rendering failed for {template}: missing variable {var}\",\n",
    "    ],\n",
    "    \"search-service\": [\n",
    "        \"Elasticsearch cluster health RED: {shards} unassigned shards\",\n",
    "        \"Search query timeout after {timeout}ms for query: {query}\",\n",
    "        \"Index {index} not found, falling back to default search\",\n",
    "        \"Aggregation query too expensive: {buckets} buckets requested\",\n",
    "        \"Reindex operation failed at document {doc_id}: {reason}\",\n",
    "    ],\n",
    "    \"recommendation-engine\": [\n",
    "        \"Model inference failed: GPU memory exhausted\",\n",
    "        \"Feature store connection timeout after {timeout}ms\",\n",
    "        \"Cold start problem for new user {user_id}: no interaction history\",\n",
    "        \"Model version mismatch: expected v{expected}, got v{actual}\",\n",
    "        \"Recommendation cache miss rate {percent}% exceeds threshold\",\n",
    "    ],\n",
    "    \"cache-service\": [\n",
    "        \"Redis cluster node {node} unreachable, failover initiated\",\n",
    "        \"Cache eviction storm: {evicted} keys evicted in {seconds}s\",\n",
    "        \"Memory usage critical: {percent}% of max, consider scaling\",\n",
    "        \"Key {key} serialization failed: object too large\",\n",
    "        \"Distributed lock acquisition timeout for key {key}\",\n",
    "    ],\n",
    "    \"auth-service\": [\n",
    "        \"Brute force attack detected from IP {ip}: {attempts} failed attempts\",\n",
    "        \"OAuth provider {provider} returned error: {error}\",\n",
    "        \"Token refresh failed for user {user_id}: refresh token revoked\",\n",
    "        \"MFA verification failed for user {user_id}: code expired\",\n",
    "        \"API key revoked due to suspicious activity\",\n",
    "        \"LDAP sync failed: connection to {server} refused\",\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info/success message templates\n",
    "info_templates = {\n",
    "    \"api-gateway\": [\n",
    "        \"Request {method} {path} completed in {duration}ms with status {status}\",\n",
    "        \"New client connection from {ip}, total active connections: {count}\",\n",
    "        \"Rate limit reset for client {ip}\",\n",
    "        \"Circuit breaker CLOSED for service {service}, resuming normal operation\",\n",
    "        \"Health check passed for all upstream services\",\n",
    "    ],\n",
    "    \"user-service\": [\n",
    "        \"User {user_id} successfully authenticated from {ip}\",\n",
    "        \"New user registration completed: {user_id} ({email})\",\n",
    "        \"Password changed successfully for user {user_id}\",\n",
    "        \"User profile updated: {user_id} changed {fields}\",\n",
    "        \"Session created for user {user_id}, expires in {hours} hours\",\n",
    "    ],\n",
    "    \"order-service\": [\n",
    "        \"Order {order_id} created successfully, total: ${amount}\",\n",
    "        \"Order {order_id} status changed: {from_status} -> {to_status}\",\n",
    "        \"Order {order_id} shipped via {carrier}, tracking: {tracking}\",\n",
    "        \"Order {order_id} delivered to {city}, {country}\",\n",
    "        \"Bulk order import completed: {count} orders processed\",\n",
    "    ],\n",
    "    \"payment-service\": [\n",
    "        \"Payment {txn_id} authorized successfully: ${amount}\",\n",
    "        \"Payment {txn_id} captured: ${amount} via {method}\",\n",
    "        \"Refund processed: ${amount} to {method}\",\n",
    "        \"Daily settlement completed: {count} transactions, ${total}\",\n",
    "        \"Payment method added for user {user_id}: {type} ending in {last4}\",\n",
    "    ],\n",
    "    \"inventory-service\": [\n",
    "        \"Stock updated for SKU {sku}: {old_qty} -> {new_qty}\",\n",
    "        \"Inventory reserved for order {order_id}: {quantity} x {sku}\",\n",
    "        \"Warehouse {warehouse_id} sync completed: {count} SKUs updated\",\n",
    "        \"Restock shipment received: {count} units for {sku}\",\n",
    "        \"Inventory audit completed: {matched} matched, {discrepancies} discrepancies\",\n",
    "    ],\n",
    "    \"notification-service\": [\n",
    "        \"Email sent to {email}: {subject}\",\n",
    "        \"Push notification delivered to {device_count} devices\",\n",
    "        \"SMS sent to {phone}: delivery confirmed\",\n",
    "        \"Notification batch processed: {count} messages in {duration}ms\",\n",
    "        \"User {user_id} notification preferences updated\",\n",
    "    ],\n",
    "    \"search-service\": [\n",
    "        \"Search query completed in {duration}ms: {results} results for '{query}'\",\n",
    "        \"Index {index} refreshed, {docs} documents searchable\",\n",
    "        \"Search suggestions generated for '{prefix}': {count} suggestions\",\n",
    "        \"Elasticsearch cluster health GREEN: {nodes} nodes, {shards} shards\",\n",
    "        \"Search analytics aggregated: {queries} queries, {clicks} clicks\",\n",
    "    ],\n",
    "    \"recommendation-engine\": [\n",
    "        \"Recommendations generated for user {user_id}: {count} items in {duration}ms\",\n",
    "        \"Model v{version} deployed successfully to {replicas} replicas\",\n",
    "        \"Feature store updated: {features} features for {users} users\",\n",
    "        \"A/B test {test_id} started: {variants} variants, {traffic}% traffic\",\n",
    "        \"Batch inference completed: {count} users processed\",\n",
    "    ],\n",
    "    \"cache-service\": [\n",
    "        \"Cache hit for key {key}: served in {duration}us\",\n",
    "        \"Cache warmed: {count} keys preloaded\",\n",
    "        \"Redis cluster rebalanced: {slots} slots migrated\",\n",
    "        \"Memory usage nominal: {percent}% of max capacity\",\n",
    "        \"Cache statistics: {hits} hits, {misses} misses, {ratio}% hit rate\",\n",
    "    ],\n",
    "    \"auth-service\": [\n",
    "        \"OAuth login successful: user {user_id} via {provider}\",\n",
    "        \"Access token issued for user {user_id}, expires in {minutes} minutes\",\n",
    "        \"API key created for user {user_id}\",\n",
    "        \"MFA enabled for user {user_id}: {method}\",\n",
    "        \"Security audit: {active} active sessions for user {user_id}\",\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack trace templates for errors\n",
    "stack_traces = [\n",
    "    \"\"\"java.lang.NullPointerException: Cannot invoke method on null object\n",
    "    at com.example.service.UserService.getUser(UserService.java:142)\n",
    "    at com.example.controller.UserController.handleRequest(UserController.java:87)\n",
    "    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:897)\n",
    "    at javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\"\"\",\n",
    "    \n",
    "    \"\"\"java.sql.SQLException: Connection pool exhausted, no available connections\n",
    "    at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:155)\n",
    "    at com.example.repository.OrderRepository.findById(OrderRepository.java:45)\n",
    "    at com.example.service.OrderService.processOrder(OrderService.java:201)\n",
    "    at com.example.controller.OrderController.createOrder(OrderController.java:63)\"\"\",\n",
    "    \n",
    "    \"\"\"redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool\n",
    "    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:84)\n",
    "    at com.example.cache.CacheService.get(CacheService.java:56)\n",
    "    at com.example.service.ProductService.getProduct(ProductService.java:78)\"\"\",\n",
    "    \n",
    "    \"\"\"org.elasticsearch.ElasticsearchTimeoutException: Timeout waiting for search response\n",
    "    at org.elasticsearch.client.RestHighLevelClient.search(RestHighLevelClient.java:1012)\n",
    "    at com.example.search.SearchService.executeSearch(SearchService.java:145)\n",
    "    at com.example.controller.SearchController.search(SearchController.java:52)\"\"\",\n",
    "    \n",
    "    \"\"\"com.stripe.exception.CardException: Your card was declined\n",
    "    at com.stripe.net.LiveStripeResponseGetter.handleError(LiveStripeResponseGetter.java:214)\n",
    "    at com.example.payment.StripePaymentGateway.charge(StripePaymentGateway.java:89)\n",
    "    at com.example.service.PaymentService.processPayment(PaymentService.java:156)\"\"\",\n",
    "    \n",
    "    \"\"\"io.grpc.StatusRuntimeException: UNAVAILABLE: upstream connect error or disconnect/reset before headers\n",
    "    at io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:271)\n",
    "    at com.example.client.InventoryClient.checkStock(InventoryClient.java:67)\n",
    "    at com.example.service.OrderService.validateOrder(OrderService.java:112)\"\"\",\n",
    "    \n",
    "    \"\"\"org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms\n",
    "    at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:999)\n",
    "    at com.example.messaging.EventPublisher.publish(EventPublisher.java:45)\n",
    "    at com.example.service.OrderService.publishOrderEvent(OrderService.java:234)\"\"\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def generate_ip():\n",
    "    return f\"{random.randint(1,255)}.{random.randint(0,255)}.{random.randint(0,255)}.{random.randint(1,254)}\"\n",
    "\n",
    "def generate_user_id():\n",
    "    return f\"user_{random.randint(10000, 99999)}\"\n",
    "\n",
    "def generate_order_id():\n",
    "    return f\"ORD-{random.randint(100000, 999999)}\"\n",
    "\n",
    "def generate_transaction_id():\n",
    "    return f\"txn_{uuid.uuid4().hex[:16]}\"\n",
    "\n",
    "def generate_trace_id():\n",
    "    return uuid.uuid4().hex\n",
    "\n",
    "def generate_span_id():\n",
    "    return uuid.uuid4().hex[:16]\n",
    "\n",
    "def fill_template(template, service_name):\n",
    "    \"\"\"Fill a template with random realistic values\"\"\"\n",
    "    replacements = {\n",
    "        \"{service}\": random.choice([s[\"name\"] for s in services]),\n",
    "        \"{timeout}\": str(random.choice([1000, 2000, 3000, 5000, 10000, 30000])),\n",
    "        \"{ip}\": generate_ip(),\n",
    "        \"{requests}\": str(random.randint(100, 1000)),\n",
    "        \"{window}\": str(random.choice([60, 300, 600])),\n",
    "        \"{reason}\": random.choice([\"connection_refused\", \"timeout\", \"invalid_response\", \"certificate_expired\", \"rate_limited\"]),\n",
    "        \"{size}\": str(random.randint(10, 100)),\n",
    "        \"{status}\": str(random.choice([200, 201, 400, 401, 403, 404, 500, 502, 503, 504])),\n",
    "        \"{message}\": random.choice([\"Internal Server Error\", \"Bad Gateway\", \"Service Unavailable\", \"Gateway Timeout\", \"OK\"]),\n",
    "        \"{user_id}\": generate_user_id(),\n",
    "        \"{waiting}\": str(random.randint(10, 100)),\n",
    "        \"{email}\": f\"user{random.randint(1000,9999)}@example.com\",\n",
    "        \"{minutes}\": str(random.randint(30, 120)),\n",
    "        \"{code}\": str(random.choice([421, 450, 451, 452, 550, 551, 552, 553, 554])),\n",
    "        \"{order_id}\": generate_order_id(),\n",
    "        \"{sku}\": f\"SKU-{random.randint(10000, 99999)}\",\n",
    "        \"{hours}\": str(random.randint(1, 48)),\n",
    "        \"{txn_id}\": generate_transaction_id(),\n",
    "        \"{score}\": str(random.randint(70, 99)),\n",
    "        \"{from_curr}\": random.choice([\"USD\", \"EUR\", \"GBP\"]),\n",
    "        \"{to_curr}\": random.choice([\"JPY\", \"CNY\", \"INR\"]),\n",
    "        \"{gateway}\": random.choice([\"stripe\", \"paypal\", \"braintree\", \"adyen\"]),\n",
    "        \"{error_code}\": random.choice([\"card_declined\", \"insufficient_funds\", \"expired_card\", \"invalid_cvc\"]),\n",
    "        \"{expected}\": str(random.randint(100, 500)),\n",
    "        \"{actual}\": str(random.randint(0, 99)),\n",
    "        \"{warehouse_id}\": f\"WH-{random.choice(['US-EAST', 'US-WEST', 'EU-CENTRAL', 'APAC'])}01\",\n",
    "        \"{quantity}\": str(random.randint(1, 100)),\n",
    "        \"{device_id}\": f\"device_{uuid.uuid4().hex[:12]}\",\n",
    "        \"{provider}\": random.choice([\"twilio\", \"sendgrid\", \"aws_sns\", \"firebase\"]),\n",
    "        \"{count}\": str(random.randint(10, 1000)),\n",
    "        \"{age}\": str(random.randint(60, 3600)),\n",
    "        \"{template}\": random.choice([\"order_confirmation\", \"password_reset\", \"welcome\", \"shipping_update\"]),\n",
    "        \"{var}\": random.choice([\"customer_name\", \"order_total\", \"tracking_number\", \"delivery_date\"]),\n",
    "        \"{shards}\": str(random.randint(1, 10)),\n",
    "        \"{query}\": random.choice([\"laptop gaming\", \"iphone case\", \"running shoes\", \"wireless headphones\"]),\n",
    "        \"{index}\": random.choice([\"products\", \"orders\", \"users\", \"logs\"]),\n",
    "        \"{buckets}\": str(random.randint(10000, 100000)),\n",
    "        \"{doc_id}\": f\"doc_{uuid.uuid4().hex[:8]}\",\n",
    "        \"{percent}\": str(random.randint(10, 50)),\n",
    "        \"{test_id}\": f\"test_{random.randint(100, 999)}\",\n",
    "        \"{node}\": f\"redis-{random.randint(1, 5)}\",\n",
    "        \"{evicted}\": str(random.randint(1000, 10000)),\n",
    "        \"{seconds}\": str(random.randint(1, 60)),\n",
    "        \"{key}\": f\"cache:{random.choice(['user', 'product', 'session', 'config'])}:{random.randint(1000, 9999)}\",\n",
    "        \"{attempts}\": str(random.randint(5, 50)),\n",
    "        \"{error}\": random.choice([\"access_denied\", \"invalid_grant\", \"invalid_client\", \"expired_token\"]),\n",
    "        \"{server}\": f\"ldap.{random.choice(['us', 'eu', 'ap'])}.corp.internal\",\n",
    "        \"{method}\": random.choice([\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"]),\n",
    "        \"{path}\": random.choice([\"/api/v1/users\", \"/api/v1/orders\", \"/api/v1/products\", \"/api/v1/search\", \"/health\"]),\n",
    "        \"{duration}\": str(random.randint(5, 2000)),\n",
    "        \"{fields}\": random.choice([\"email,phone\", \"name\", \"address\", \"preferences\"]),\n",
    "        \"{amount}\": f\"{random.randint(10, 500)}.{random.randint(0, 99):02d}\",\n",
    "        \"{from_status}\": random.choice([\"pending\", \"processing\", \"shipped\"]),\n",
    "        \"{to_status}\": random.choice([\"processing\", \"shipped\", \"delivered\"]),\n",
    "        \"{carrier}\": random.choice([\"fedex\", \"ups\", \"usps\", \"dhl\"]),\n",
    "        \"{tracking}\": f\"{random.choice(['1Z', 'FX', 'DHL'])}{random.randint(1000000000, 9999999999)}\",\n",
    "        \"{city}\": random.choice([\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"London\", \"Paris\", \"Tokyo\"]),\n",
    "        \"{country}\": random.choice([\"USA\", \"UK\", \"France\", \"Germany\", \"Japan\", \"Canada\"]),\n",
    "        \"{old_qty}\": str(random.randint(10, 100)),\n",
    "        \"{new_qty}\": str(random.randint(0, 200)),\n",
    "        \"{matched}\": str(random.randint(900, 1000)),\n",
    "        \"{discrepancies}\": str(random.randint(0, 10)),\n",
    "        \"{subject}\": random.choice([\"Order Confirmation\", \"Shipping Update\", \"Password Reset\", \"Welcome!\"]),\n",
    "        \"{device_count}\": str(random.randint(1, 5)),\n",
    "        \"{phone}\": f\"+1{random.randint(2000000000, 9999999999)}\",\n",
    "        \"{results}\": str(random.randint(10, 10000)),\n",
    "        \"{docs}\": str(random.randint(10000, 1000000)),\n",
    "        \"{prefix}\": random.choice([\"lapt\", \"phon\", \"shoe\", \"head\"]),\n",
    "        \"{nodes}\": str(random.randint(3, 10)),\n",
    "        \"{queries}\": str(random.randint(1000, 100000)),\n",
    "        \"{clicks}\": str(random.randint(100, 10000)),\n",
    "        \"{version}\": f\"{random.randint(1, 5)}.{random.randint(0, 9)}.{random.randint(0, 99)}\",\n",
    "        \"{replicas}\": str(random.randint(2, 10)),\n",
    "        \"{features}\": str(random.randint(50, 200)),\n",
    "        \"{users}\": str(random.randint(10000, 1000000)),\n",
    "        \"{variants}\": str(random.randint(2, 4)),\n",
    "        \"{traffic}\": str(random.randint(5, 50)),\n",
    "        \"{slots}\": str(random.randint(100, 1000)),\n",
    "        \"{hits}\": str(random.randint(10000, 100000)),\n",
    "        \"{misses}\": str(random.randint(100, 1000)),\n",
    "        \"{ratio}\": str(random.randint(90, 99)),\n",
    "        \"{active}\": str(random.randint(1, 10)),\n",
    "        \"{type}\": random.choice([\"visa\", \"mastercard\", \"amex\"]),\n",
    "        \"{last4}\": f\"{random.randint(1000, 9999)}\",\n",
    "        \"{total}\": f\"{random.randint(10000, 100000)}.{random.randint(0, 99):02d}\",\n",
    "    }\n",
    "    \n",
    "    result = template\n",
    "    for placeholder, value in replacements.items():\n",
    "        result = result.replace(placeholder, value)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_log_entry(base_time, service_info):\n",
    "    \"\"\"Generate a single log entry\"\"\"\n",
    "    \n",
    "    # Pick log level with weighted randomness\n",
    "    log_level = random.choices(log_levels, weights=log_level_weights)[0]\n",
    "    \n",
    "    service_name = service_info[\"name\"]\n",
    "    \n",
    "    # Generate message based on log level\n",
    "    if log_level in [\"ERROR\", \"FATAL\"]:\n",
    "        templates = error_templates.get(service_name, error_templates[\"api-gateway\"])\n",
    "        message = fill_template(random.choice(templates), service_name)\n",
    "        stack_trace = random.choice(stack_traces) if random.random() < 0.7 else None\n",
    "    elif log_level == \"WARN\":\n",
    "        # Mix of error-like warnings and info-like warnings\n",
    "        if random.random() < 0.5:\n",
    "            templates = error_templates.get(service_name, error_templates[\"api-gateway\"])\n",
    "        else:\n",
    "            templates = info_templates.get(service_name, info_templates[\"api-gateway\"])\n",
    "        message = fill_template(random.choice(templates), service_name)\n",
    "        stack_trace = None\n",
    "    else:  # DEBUG, INFO\n",
    "        templates = info_templates.get(service_name, info_templates[\"api-gateway\"])\n",
    "        message = fill_template(random.choice(templates), service_name)\n",
    "        stack_trace = None\n",
    "    \n",
    "    # Generate timestamp with some randomness\n",
    "    timestamp = base_time + timedelta(\n",
    "        seconds=random.randint(0, 3600),\n",
    "        milliseconds=random.randint(0, 999)\n",
    "    )\n",
    "    \n",
    "    # Generate distributed tracing IDs\n",
    "    trace_id = generate_trace_id()\n",
    "    span_id = generate_span_id()\n",
    "    \n",
    "    log_entry = {\n",
    "        \"@timestamp\": timestamp.isoformat(),\n",
    "        \"log.level\": log_level,\n",
    "        \"message\": message,\n",
    "        \"service.name\": service_name,\n",
    "        \"host.name\": service_info[\"host\"],\n",
    "        \"host.environment\": service_info[\"env\"],\n",
    "        \"trace.id\": trace_id,\n",
    "        \"span.id\": span_id,\n",
    "        \"process.pid\": random.randint(1000, 65535),\n",
    "        \"process.thread.name\": f\"worker-{random.randint(1, 16)}\",\n",
    "    }\n",
    "    \n",
    "    # Add HTTP-related fields for gateway and some services\n",
    "    if service_name in [\"api-gateway\", \"user-service\", \"order-service\", \"search-service\"]:\n",
    "        http_status = random.choices(http_status_codes, weights=http_status_weights)[0]\n",
    "        log_entry[\"http.request.method\"] = random.choice([\"GET\", \"POST\", \"PUT\", \"DELETE\"])\n",
    "        log_entry[\"http.response.status_code\"] = http_status\n",
    "        log_entry[\"http.request.duration_ms\"] = random.randint(1, 5000)\n",
    "        log_entry[\"client.ip\"] = generate_ip()\n",
    "        log_entry[\"user_agent.original\"] = random.choice(user_agents)\n",
    "    \n",
    "    # Add stack trace for errors\n",
    "    if stack_trace:\n",
    "        log_entry[\"error.stack_trace\"] = stack_trace\n",
    "        log_entry[\"error.type\"] = stack_trace.split(\":\")[0]\n",
    "    \n",
    "    return log_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index with appropriate mapping\n",
    "index_name = \"application-logs\"\n",
    "\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"@timestamp\": {\"type\": \"date\"},\n",
    "            \"log.level\": {\"type\": \"keyword\"},\n",
    "            \"message\": {\"type\": \"text\"},\n",
    "            \"service.name\": {\"type\": \"keyword\"},\n",
    "            \"host.name\": {\"type\": \"keyword\"},\n",
    "            \"host.environment\": {\"type\": \"keyword\"},\n",
    "            \"trace.id\": {\"type\": \"keyword\"},\n",
    "            \"span.id\": {\"type\": \"keyword\"},\n",
    "            \"process.pid\": {\"type\": \"integer\"},\n",
    "            \"process.thread.name\": {\"type\": \"keyword\"},\n",
    "            \"http.request.method\": {\"type\": \"keyword\"},\n",
    "            \"http.response.status_code\": {\"type\": \"integer\"},\n",
    "            \"http.request.duration_ms\": {\"type\": \"integer\"},\n",
    "            \"client.ip\": {\"type\": \"ip\"},\n",
    "            \"user_agent.original\": {\"type\": \"text\"},\n",
    "            \"error.stack_trace\": {\"type\": \"text\"},\n",
    "            \"error.type\": {\"type\": \"keyword\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Delete index if exists and recreate\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "    print(f\"Deleted existing index: {index_name}\")\n",
    "\n",
    "es.indices.create(index=index_name, body=mapping)\n",
    "print(f\"Created index: {index_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate logs for the past 7 days\n",
    "def generate_and_index_logs(num_logs=10000):\n",
    "    print(f\"Generating {num_logs} log entries...\")\n",
    "    \n",
    "    actions = []\n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(days=7)\n",
    "    \n",
    "    for i in range(num_logs):\n",
    "        # Random time within the past 7 days\n",
    "        base_time = start_time + timedelta(\n",
    "            seconds=random.randint(0, int((end_time - start_time).total_seconds()))\n",
    "        )\n",
    "        \n",
    "        service_info = random.choice(services)\n",
    "        log_entry = generate_log_entry(base_time, service_info)\n",
    "        \n",
    "        actions.append({\n",
    "            \"_index\": index_name,\n",
    "            \"_source\": log_entry\n",
    "        })\n",
    "        \n",
    "        # Bulk index in batches\n",
    "        if len(actions) >= 1000:\n",
    "            helpers.bulk(es, actions)\n",
    "            print(f\"Indexed {i + 1} logs...\")\n",
    "            actions = []\n",
    "    \n",
    "    # Index remaining\n",
    "    if actions:\n",
    "        helpers.bulk(es, actions)\n",
    "    \n",
    "    print(f\"Successfully indexed {num_logs} log entries!\")\n",
    "\n",
    "# Generate 10,000 log entries\n",
    "generate_and_index_logs(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data\n",
    "es.indices.refresh(index=index_name)\n",
    "count = es.count(index=index_name)[\"count\"]\n",
    "print(f\"\\nTotal documents in '{index_name}': {count}\")\n",
    "\n",
    "# Show distribution by log level\n",
    "agg_result = es.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"size\": 0,\n",
    "        \"aggs\": {\n",
    "            \"by_level\": {\n",
    "                \"terms\": {\"field\": \"log.level\"}\n",
    "            },\n",
    "            \"by_service\": {\n",
    "                \"terms\": {\"field\": \"service.name\", \"size\": 20}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nLog level distribution:\")\n",
    "for bucket in agg_result[\"aggregations\"][\"by_level\"][\"buckets\"]:\n",
    "    print(f\"  {bucket['key']}: {bucket['doc_count']}\")\n",
    "\n",
    "print(\"\\nService distribution:\")\n",
    "for bucket in agg_result[\"aggregations\"][\"by_service\"][\"buckets\"]:\n",
    "    print(f\"  {bucket['key']}: {bucket['doc_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample error logs (great for LLM analysis)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE ERROR LOGS (perfect for LLM analysis):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "error_logs = es.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"terms\": {\"log.level\": [\"ERROR\", \"FATAL\"]}\n",
    "        },\n",
    "        \"size\": 5,\n",
    "        \"sort\": [{\"@timestamp\": \"desc\"}]\n",
    "    }\n",
    ")\n",
    "\n",
    "for hit in error_logs[\"hits\"][\"hits\"]:\n",
    "    source = hit[\"_source\"]\n",
    "    print(f\"\\n[{source['log.level']}] {source['service.name']} @ {source['@timestamp']}\")\n",
    "    print(f\"  Message: {source['message']}\")\n",
    "    if 'error.type' in source:\n",
    "        print(f\"  Error Type: {source['error.type']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Data generation complete! Ready for LLM-powered log analysis.\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nExample elastic-script queries you can now run:\")\n",
    "print(\"  - LLM_SUMMARIZE(<error logs from payment-service>)\")\n",
    "print(\"  - LLM_CLASSIFY(<log message>, ['critical', 'warning', 'info'])\")\n",
    "print(\"  - LLM_EXTRACT(<stack trace>, ['exception_type', 'root_cause', 'affected_service'])\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}